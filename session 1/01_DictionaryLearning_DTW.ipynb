{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning for Time Series (Master MVA)**\n",
    "\n",
    "- TP1, Thursday 19<sup>th</sup> October 2023\n",
    "- [Link to the class material.](http://www.laurentoudre.fr/ast.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we illustrate two concepts:\n",
    "- convolutional dictionary learning (CDL),\n",
    "- dynamic time warping (DTW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dtw import dtw\n",
    "from IPython.display import Audio, display\n",
    "from loadmydata.load_uea_ucr import load_uea_ucr_data\n",
    "from matplotlib.colors import rgb2hex\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from alphacsc import learn_d_z\n",
    "try:\n",
    "    from alphacsc.utils import construct_X\n",
    "except:\n",
    "    from alphacsc.utils.convolution import construct_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CDL(signal, Z, D, figsize=(15, 10)):\n",
    "    \"\"\"Plot the learned dictionary `D` and the associated sparse codes `Z`.\n",
    "\n",
    "    `signal` is an univariate signal of shape (n_samples,) or (n_samples, 1).\n",
    "    \"\"\"\n",
    "    (atom_length, n_atoms) = np.shape(D)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(n_atoms + 1, 3, (2, 3))\n",
    "    plt.plot(signal)\n",
    "    for i in range(n_atoms):\n",
    "        plt.subplot(n_atoms + 1, 3, 3 * i + 4)\n",
    "        plt.plot(D[:, i])\n",
    "        plt.subplot(n_atoms + 1, 3, (3 * i + 5, 3 * i + 6))\n",
    "        plt.plot(Z[:, i])\n",
    "        plt.ylim((np.min(Z), np.max(Z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_distance_matrix_as_table(\n",
    "    distance_matrix, labels=None, figsize=(8, 2)\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axis(\"tight\")\n",
    "    ax.axis(\"off\")\n",
    "    norm = mpl.colors.Normalize()\n",
    "    cell_colours_hex = np.empty(shape=distance_matrix.shape, dtype=object)\n",
    "    cell_colours_rgba = plt.get_cmap(\"magma\")(norm(distance_matrix))\n",
    "\n",
    "    for i in range(distance_matrix.shape[0]):\n",
    "        for j in range(i + 1, distance_matrix.shape[0]):\n",
    "            cell_colours_hex[i, j] = rgb2hex(\n",
    "                cell_colours_rgba[i, j], keep_alpha=True\n",
    "            )\n",
    "            cell_colours_hex[j, i] = cell_colours_hex[i, j]\n",
    "\n",
    "    if labels is not None:\n",
    "        _ = ax.table(\n",
    "            cellText=distance_matrix,\n",
    "            colLabels=labels,\n",
    "            rowLabels=labels,\n",
    "            loc=\"center\",\n",
    "            cellColours=cell_colours_hex,\n",
    "        )\n",
    "    else:\n",
    "        _ = ax.table(\n",
    "            cellText=distance_matrix,\n",
    "            loc=\"center\",\n",
    "            cellColours=cell_colours_hex,\n",
    "        )\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_largest(\n",
    "    arr: np.ndarray, n_largest: int = 3\n",
    ") -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"Return the n largest values and associated indexes of an array.\n",
    "\n",
    "    (In decreasing order of value.)\n",
    "    \"\"\"\n",
    "    indexes = np.argsort(arr)[-n_largest:][::-1]\n",
    "    if n_largest == 1:\n",
    "        indexes = np.array(indexes)\n",
    "    values = np.take(arr, indexes)\n",
    "    return values, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_ax(figsize=(15, 5)):\n",
    "    return plt.subplots(figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional dictionary learning (CDL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Task is to classify the nature of the heartbeat signal.\n",
    "\n",
    "Heart sound recordings were sourced from several contributors around the world, collected at either a clinical or nonclinical environment, from both healthy subjects and pathological patients.\n",
    "Each series represent the aplitude of the singal over time.\n",
    "\n",
    "Heart sound recordings were sourced from several contributors around the world, collected at either a clinical or nonclinical environment, from both healthy subjects and pathological patients.\n",
    "The heart sound recordings were collected from different locations on the body. The typical four locations are aortic area, pulmonic area, tricuspid area and mitral area, but could be one of nine different locations.\n",
    "The sounds were divided into two classes: normal and abnormal. The normal recordings were from healthy subjects and the abnormal ones were from patients with a confirmed cardiac diagnosis.\n",
    "The patients suffer from a variety of illnesses, but typically they are heart valve defects and coronary artery disease patients.\n",
    "Heart valve defects include mitral valve prolapse, mitral regurgitation, aortic stenosis and valvular surgery. All the recordings from the patients were generally labeled as abnormal.\n",
    "Both healthy subjects and pathological patients include both children and adults.\n",
    "\n",
    "Data was recorded at 2,000Hz.\n",
    "Data was truncated to the shortest instance.\n",
    "\n",
    "Original data can be found here:\n",
    "https://www.physionet.org/physiobank/database/challenge/2016/\n",
    "\n",
    "Original paper:\n",
    "Goldberger AL, Amaral LA, Glass L, Hausdorff JM, Ivanov PC, Mark RG, Mietus JE, Moody GB, Peng CK, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals. circulation. 2000 Jun 13;101(23):e215-20.\n",
    "\n",
    "Correspondence should be addressed to Ary L. Goldberger:\n",
    "ary@astro.bidmc.harvard.edu\n",
    "\n",
    "Instances: 409\n",
    "\n",
    "Time series length: 18,530\n",
    "\n",
    "Classes:\n",
    "- Normal (110)\n",
    "- Abnormal (299)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(\"BinaryHeartbeat.csv\").reshape((204, 18530, 1))\n",
    "y_train = np.array(['Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>What is the sampling frequency of those sounds?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQUENCY = ...  # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot a signal from each class (normal and abnormal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(nrows=1, ncols=2, figsize=(20, 3), sharey=True)\n",
    "fig.tight_layout()\n",
    "for ind, ax in zip([1, 200], ax_arr):\n",
    "    s = X_train[ind]\n",
    "    tt = np.arange(s.size) / FREQUENCY\n",
    "    ax.plot(tt, s)\n",
    "    ax.set_xlim(0, s.size / FREQUENCY)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    _ = ax.set_title(f\"label: {data.y_train[ind]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the time series are sound signals, we can choose one and listen to it.\n",
    "\n",
    "for ind in [1, 200]:\n",
    "    signal = X_train[ind]\n",
    "    label = data.y_train[ind]\n",
    "    print(label)\n",
    "    display(Audio(signal.flatten(), rate=FREQUENCY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the subsequent study, we select only 6 elements (3 from each classe) from the complete data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sample = [0, 1, 2, 190, 191, 192]  # 3 Normal, 3 Abnormal\n",
    "X = np.take(\n",
    "    X_train, sub_sample, axis=0\n",
    ").squeeze()  # shape (n_series, n_samples)\n",
    "y = np.take(y_train, sub_sample, axis=0)  # shape (n_series,)\n",
    "\n",
    "# normalize signals (zero mean, unit variance).\n",
    "X -= X.mean(axis=1).reshape(-1, 1)\n",
    "X /= X.std(axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2\n",
    "signal = X[ind]\n",
    "label = y[ind]\n",
    "\n",
    "fig, ax_arr = plt.subplots(nrows=1, ncols=2, figsize=(20, 3), sharey=True)\n",
    "fig.tight_layout()\n",
    "ax = ax_arr[0]\n",
    "\n",
    "n_samples = signal.size\n",
    "tt = np.arange(n_samples) / FREQUENCY\n",
    "ax.plot(tt, signal)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_xlim(0, n_samples / FREQUENCY)\n",
    "\n",
    "ax.set_title(f\"label: {label}\")\n",
    "\n",
    "ax = ax_arr[1]\n",
    "start, end = 5000, 7500  # change here to zoom somewhere else\n",
    "ax.plot(tt[start:end], signal[start:end])\n",
    "ax.set_xlim(tt[start], tt[end])\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "_ = ax.set_title(f\"Zoom on [{start/FREQUENCY:.2f}s, {end/FREQUENCY:.2f}s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Roughly, what is the duration of the important phenomenon (the heartbeat)?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDL on a single signal\n",
    "\n",
    "For a 1D signal $\\mathbf{x}\\in\\mathbb{R}^N$ with $N$ samples, the convolutional dictionary learning tasks amounts to solving the following optimization problem:\n",
    "\n",
    "$$\n",
    "\\min_{(\\mathbf{d}_k)_k, (\\mathbf{z}_k)_k \\\\ \\lVert\\mathbf{d}_k\\rVert^2\\leq 1} \\quad (1/2)\\left\\lVert \\mathbf{x} - \\sum_{k=1}^K \\mathbf{z}_k * \\mathbf{d}_k \\right\\rVert^2 \\quad + \\quad\\lambda \\sum_{k=1}^K \\lVert\\mathbf{z}_k\\rVert_1\n",
    "$$\n",
    "\n",
    "where $\\mathbf{d}_k\\in\\mathbb{R}^L$ are the $K$ dictionary atoms (patterns), $\\mathbf{z}_k\\in\\mathbb{R}^{N-L+1}$ are activations signals, and $\\lambda>0$ is the sparsity constraint.\n",
    "\n",
    "This problem is not convex with respect to the couple $(\\mathbf{d}_k)_k, (\\mathbf{z}_k)_k$ but convex when the subproblems are taken individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>What are the parameters that a user must calibrate when using CDL?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply CDL on a single signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a signal\n",
    "signal = X[2]\n",
    "data = signal[np.newaxis, :]  # shape (1, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to change\n",
    "n_atoms = 3  # K\n",
    "atom_length = 2000  # L\n",
    "penalty = 3  # lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# learning a dictionary and codes\n",
    "pobj, _, d_hat, z_hat, _ = learn_d_z(\n",
    "    X=data,\n",
    "    n_atoms=n_atoms,\n",
    "    n_times_atom=atom_length,\n",
    "    reg=penalty,\n",
    "    n_iter=30,\n",
    "    n_jobs=4,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plot_CDL(signal, z_hat.T.squeeze(), d_hat.T.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>How does the number of activation evolve when the sparsity penalty changes?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Looking at the sparse codes, can you tell:</p>\n",
    "    <ul>    \n",
    "    <li>How many times each atom is activated?</li>\n",
    "    <li>What is the compression rate (number of non-zero coefficients in the sparse codes / signal length)?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the learned dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, atom in enumerate(d_hat):\n",
    "    print(f\"Atom {k}\")\n",
    "    display(Audio(atom, rate=FREQUENCY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us look at the reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction with the dictionary and the sparse codes\n",
    "reconstruction = construct_X(z_hat, d_hat).squeeze()\n",
    "\n",
    "fig, ax = fig_ax()\n",
    "tt = np.arange(signal.shape[0])\n",
    "ax.plot(tt, signal, label=\"original\", alpha=0.5)\n",
    "ax.plot(tt, reconstruction, label=\"reconstructed\")\n",
    "\n",
    "ax.set_title(f\"Reconstruction MSE: {np.mean((signal - reconstruction)**2):.2e}\")\n",
    "\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>How does reconstruction error evolve when the sparsity penalty changes?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(\n",
    "    nrows=n_atoms // 3 + 1,\n",
    "    ncols=3,\n",
    "    figsize=(20, 4 * (n_atoms // 3 + 1)),\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "for k in range(n_atoms):\n",
    "    ax = ax_arr.flatten()[k]\n",
    "    reconstruted_with_one_atom = construct_X(\n",
    "        z_hat[k, np.newaxis, :, :], d_hat[k, np.newaxis, :]\n",
    "    ).squeeze()\n",
    "    ax.plot(range(start, end), signal[start:end])\n",
    "    ax.plot(\n",
    "        range(start, end),\n",
    "        reconstruted_with_one_atom[start:end],\n",
    "    )\n",
    "    ax.set_title(f\"Atom {k} only\")\n",
    "\n",
    "ax = ax_arr.flatten()[n_atoms]\n",
    "ax.plot(range(start, end), signal[start:end])\n",
    "ax.plot(\n",
    "    range(start, end),\n",
    "    reconstruction[start:end],\n",
    ")\n",
    "_ = ax.set_title(f\"All atoms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Rerun the dictionary learning and sparse coding. What do you observe on the motif shape? And the reconstruction error?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDL on the whole data set\n",
    "\n",
    "In this section, we apply CDL on the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following, we fix the number of atoms and their length\n",
    "n_atoms = 5\n",
    "atom_length = 1500\n",
    "penalty = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pobj, _, d_hat, z_hat, _ = learn_d_z(\n",
    "    X=X,\n",
    "    n_atoms=n_atoms,\n",
    "    n_times_atom=atom_length,\n",
    "    reg=penalty,\n",
    "    verbose=1,\n",
    "    n_jobs=8,\n",
    "    n_iter=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot each of the learned atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(\n",
    "    nrows=n_atoms // 3 + 1,\n",
    "    ncols=3,\n",
    "    figsize=(20, 4 * (n_atoms // 3 + 1)),\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "for k, (atom, ax) in enumerate(zip(d_hat, ax_arr.flatten())):\n",
    "    ax.plot(atom)\n",
    "    ax.set_xlim(0, atom.size)\n",
    "    ax.set_title(f\"Atom {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each signal of the data set, we compute the number of non-zeros activations and the reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, (label, signal) in enumerate(zip(y, X)):\n",
    "    codes = z_hat[:, k, :]\n",
    "    reconstruction = construct_X(codes[:, np.newaxis, :], d_hat).squeeze()\n",
    "    error = np.mean((signal - reconstruction) ** 2)\n",
    "    nnz_activations = (codes > 1e-3).sum()\n",
    "\n",
    "    # select the used atoms\n",
    "    most_used_atoms_activations, most_used_atoms_indexes = get_n_largest(\n",
    "        (codes > 1e-3).sum(axis=1), n_largest=1\n",
    "    )\n",
    "    most_used_atom_msg = \", \".join(\n",
    "        f\"{ind} ({acti*100/nnz_activations:.1f}%)\"\n",
    "        for (acti, ind) in zip(\n",
    "            most_used_atoms_activations, most_used_atoms_indexes\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        f\"Label: {label}, MSE: {error:.2f}, non-zero activations: {nnz_activations}, most used atoms: {most_used_atom_msg}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `Audio` function, we can listen to the learned dictionary and the reconstructed signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, (label, signal) in enumerate(zip(y, X)):\n",
    "    codes = z_hat[:, k, :]\n",
    "    reconstruction = construct_X(codes[:, np.newaxis, :], d_hat).squeeze()\n",
    "\n",
    "    print(label)\n",
    "    print(\"\\tOriginal\", end=\" \")\n",
    "    display(Audio(signal.flatten(), rate=FREQUENCY))\n",
    "    print(\"\\tReconstruction\", end=\" \")\n",
    "    display(Audio(reconstruction, rate=FREQUENCY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise has been removed. For the worst approximated signal, some hearbeats have been skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance between signals (DTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FiftyWords is a data set of word outlines taken from the George\n",
    "Washington library by T. Rath and used in the paper \"Word image\n",
    "matching using dynamic time warping\", CVPR 2003.\n",
    "\n",
    "Each case is a word. A series is formed by taking the height\n",
    "profile of the word.\n",
    "\n",
    "![image.png](attachment:8305b0d4-2097-497d-ae08-7a125fc7a2cf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we only deal with the top profile (in red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = np.loadtxt(\"dtw_X_train.csv\").reshape((450, 270, 1))\n",
    "labels = np.array(['9', '18', '1', '5', '4', '3', '25', '3', '48', '1', '12', '12', '47', '42', '31', '3', '7', '17', '12', '14', '1', '1', '8', '11', '1', '4', '6', '29', '13', '2', '6', '3', '1', '3', '13', '18', '13', '9', '5', '44', '2', '30', '3', '2', '8', '2', '9', '4', '9', '13', '5', '13', '2', '6', '39', '2', '10', '8', '2', '8', '30', '48', '4', '29', '10', '44', '5', '36', '19', '22', '32', '1', '7', '15', '2', '10', '3', '18', '3', '35', '39', '19', '3', '4', '10', '3', '12', '6', '40', '1', '39', '8', '19', '38', '1', '38', '1', '20', '7', '37', '9', '38', '30', '3', '37', '22', '16', '3', '27', '17', '28', '26', '21', '4', '4', '6', '18', '6', '30', '3', '14', '7', '35', '12', '21', '3', '4', '2', '17', '10', '49', '45', '3', '37', '36', '28', '8', '11', '7', '5', '47', '17', '1', '4', '2', '48', '12', '11', '9', '22', '25', '9', '32', '50', '47', '1', '44', '35', '17', '24', '18', '7', '1', '14', '8', '31', '30', '16', '5', '32', '11', '1', '3', '2', '3', '5', '13', '14', '12', '2', '46', '36', '6', '45', '2', '7', '7', '2', '3', '2', '1', '14', '2', '1', '2', '23', '6', '19', '23', '50', '1', '10', '7', '1', '2', '12', '13', '2', '36', '2', '12', '3', '1', '14', '1', '3', '45', '10', '2', '11', '2', '28', '21', '2', '1', '3', '3', '44', '2', '1', '7', '4', '17', '5', '3', '48', '35', '12', '1', '1', '14', '8', '16', '43', '21', '23', '1', '2', '42', '33', '27', '1', '2', '26', '2', '1', '15', '32', '2', '2', '20', '22', '18', '46', '5', '9', '47', '2', '18', '32', '2', '41', '34', '29', '45', '31', '14', '46', '21', '1', '1', '13', '37', '1', '1', '18', '4', '40', '2', '27', '19', '20', '7', '38', '20', '26', '43', '2', '17', '2', '32', '40', '10', '19', '44', '16', '19', '15', '2', '4', '24', '33', '3', '16', '4', '33', '6', '33', '1', '11', '43', '4', '3', '13', '4', '19', '2', '7', '1', '12', '20', '3', '1', '1', '2', '11', '4', '36', '7', '1', '35', '1', '19', '30', '1', '15', '5', '1', '6', '2', '6', '48', '10', '49', '28', '29', '23', '2', '2', '37', '6', '2', '1', '6', '11', '4', '6', '1', '26', '40', '34', '28', '6', '20', '39', '10', '2', '15', '1', '13', '5', '7', '2', '3', '12', '1', '13', '3', '9', '43', '16', '8', '4', '3', '33', '24', '3', '26', '1', '5', '1', '26', '21', '12', '23', '3', '32', '28', '46', '2', '20', '27', '34', '11', '13', '1', '9', '21', '2', '8', '1', '8', '2', '1', '36', '44', '15', '3', '13', '2', '23', '1', '9', '1', '7', '4', '7', '13', '35', '11', '22', '24', '1', '2', '1', '4', '15', '2', '5', '3'])\n",
    "\n",
    "# normalize signals (zero mean, unit variance).\n",
    "profiles -= profiles.mean(axis=1).reshape(-1, 1, 1)\n",
    "profiles /= profiles.std(axis=1).reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_1, label_1 = profiles[0].flatten(), labels[0]\n",
    "word_2, label_2 = profiles[1].flatten(), labels[1]\n",
    "fig, ax = fig_ax()\n",
    "ax.plot(word_1, label=label_1)\n",
    "ax.plot(word_2, label=label_2)\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTW between two signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = dtw(word_1, word_2, keep_internals=True)\n",
    "fig, ax = fig_ax()\n",
    "ax.plot(word_1, label=label_1)\n",
    "ax.plot(word_2, label=label_2)\n",
    "plt.title(f\"DTW: {alignment.distance:.2f}\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment.plot(type=\"threeway\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment.plot(type=\"twoway\", offset=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Write a function  which computes the DTW distance between two signals: <tt>get_dtw_distance(signal_1: np.ndarray, signal_2: np.ndarray)->float</tt>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Choose a word and plot the most similar and the most dissimilar, according to the DTW. In addition, print the associated labels.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering a small subset\n",
    "\n",
    "Out of the whole data set, let us choose 6 word profiles from 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few profiles with two different classes\n",
    "keep_mask = np.isin(labels, [\"31\", \"34\"])\n",
    "labels_sub = labels[keep_mask]\n",
    "profiles_sub = profiles[keep_mask]\n",
    "# reorder by label\n",
    "order_indexes = labels_sub.argsort()\n",
    "labels_sub = labels_sub[order_indexes]\n",
    "profiles_sub = profiles_sub[order_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the distance matrix $D$ of this smaller data set: $D_{ij} = d(x_i, x_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "distance_matrix = np.zeros(\n",
    "    (profiles_sub.shape[0], profiles_sub.shape[0]), dtype=float\n",
    ")\n",
    "\n",
    "for row in range(profiles_sub.shape[0]):\n",
    "    for col in range(row + 1, profiles_sub.shape[0]):\n",
    "        distance_matrix[row, col] = get_dtw_distance(\n",
    "            profiles_sub[row], profiles_sub[col]\n",
    "        )\n",
    "        distance_matrix[col, row] = distance_matrix[row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = display_distance_matrix_as_table(\n",
    "    np.round(distance_matrix, 2), labels=labels_sub\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Create the same plot (distance matrix) with the Euclidean distance instead of the DTW. What do you observe?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering on a larger subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the DTW, we can cluster a large set of data (43 words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few profiles with two different classes\n",
    "keep_mask = np.isin(labels, [\"4\", \"6\", \"14\"])\n",
    "profiles_sub = profiles[keep_mask]\n",
    "labels_sub = labels[keep_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the distance matrix with the DTW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of the previous double for loop, we can use scipy function pdist\n",
    "distance_matrix = pdist(\n",
    "    profiles_sub.squeeze(), metric=get_dtw_distance\n",
    ")  # condensed distance matrix\n",
    "# Compute linkage matrix using the 'Ward' criterion\n",
    "linkage = hierarchy.ward(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the linkage as a dendogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = fig_ax((20, 10))\n",
    "\n",
    "cut_threshold = 100\n",
    "\n",
    "dendro = hierarchy.dendrogram(\n",
    "    linkage,\n",
    "    ax=ax,\n",
    "    labels=labels_sub,\n",
    "    color_threshold=cut_threshold,\n",
    "    distance_sort=True,\n",
    ")\n",
    "ax.axhline(cut_threshold, ls=\"--\", color=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(squareform(distance_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>Do the same clustering with the Euclidean distance instead. Plot the linkage as a dendogram.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <p><b>Question</b></p>\n",
    "    <p>In the previous dendrograms, change the <tt>cut_threshold</tt> argument to have homogeneous clusters (as much as possible).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
